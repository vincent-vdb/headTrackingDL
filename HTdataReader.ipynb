{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vdel\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, MaxPooling2D, Conv2D, Flatten, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRaw = pd.read_csv('totHTdataFile.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77160\n",
      "158449\n",
      "13215\n"
     ]
    }
   ],
   "source": [
    "print(len(dataRaw[dataRaw.valid == 0]))\n",
    "print(len(dataRaw))\n",
    "print(len(np.unique(dataRaw.id)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13215, 20, 2)\n",
      "(13215, 20)\n"
     ]
    }
   ],
   "source": [
    "#Shape the data\n",
    "maxBlobs = 20\n",
    "\n",
    "ids = np.unique(dataRaw.id)\n",
    "\n",
    "nPts = len(ids)\n",
    "xinput = np.zeros((nPts, maxBlobs))\n",
    "yinput = np.zeros((nPts, maxBlobs))\n",
    "targetValue = np.zeros((nPts, maxBlobs))\n",
    "#print(dataRaw[dataRaw.id == ids[0]]['x'])\n",
    "\n",
    "for iid in range(nPts) :\n",
    "    tmpNbPts = len(dataRaw[dataRaw.id == ids[iid]])\n",
    "    if(tmpNbPts<maxBlobs):\n",
    "        xinput[iid,:tmpNbPts] = dataRaw[dataRaw.id == ids[iid]]['x'].values\n",
    "        yinput[iid,:tmpNbPts] = dataRaw[dataRaw.id == ids[iid]]['y'].values\n",
    "        targetValue[iid,:tmpNbPts] = dataRaw[dataRaw.id == ids[iid]]['valid'].values\n",
    "#    for data in dataRaw[dataRaw.id == ids[iid]]:\n",
    "#        xinput\n",
    "\n",
    "xinput = np.reshape(xinput, (xinput.shape[0], xinput.shape[1], 1))\n",
    "yinput = np.reshape(yinput, (yinput.shape[0], yinput.shape[1], 1))\n",
    "xtot = np.concatenate((xinput, yinput), axis=2)\n",
    "\n",
    "print(xtot.shape)\n",
    "print(targetValue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12754\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17181153fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check how much points are kept\n",
    "nbPts = np.sum(targetValue>0.5, axis=1)\n",
    "\n",
    "print(len(nbPts))\n",
    "\n",
    "plt.hist(nbPts)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12754 12754\n"
     ]
    }
   ],
   "source": [
    "goodPoints = np.where((nbPts<7) & (nbPts > 1))\n",
    "xtot = xtot[goodPoints]\n",
    "targetValue = targetValue[goodPoints]\n",
    "print(len(xtot), len(targetValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "xtrain, ytrain = shuffle(xtot, targetValue, random_state=0)\n",
    "xvalid = xtrain[10000:]\n",
    "#xtest = xtrain[2500:]\n",
    "xtrain = xtrain[:10000]\n",
    "yvalid = ytrain[10000:]\n",
    "#ytest = ytrain[2500:]\n",
    "ytrain = ytrain[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(Xshape):\n",
    "    \n",
    "    mod = Sequential()\n",
    "    \n",
    "    mod.add(Reshape((Xshape[0]*Xshape[1],), input_shape=(Xshape)))\n",
    "    mod.add(Dense(32, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.)))\n",
    "    mod.add(Dense(32, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.)))\n",
    "    mod.add(Dense(32, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.)))\n",
    "    mod.add(Dense(32, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.)))\n",
    "    mod.add(Dense(32, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.)))\n",
    "    mod.add(Dense(32, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.)))\n",
    "    mod.add(Dense(32, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.)))\n",
    "    mod.add(Dense(32, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.)))\n",
    "    mod.add(Dense(32, activation='relu', kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.)))\n",
    "\n",
    "    mod.add(Dense(Xshape[0], activation='sigmoid', kernel_initializer='glorot_normal'))\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = model(xtot.shape[1:])\n",
    "opt = optimizers.Adam(lr=0.0001)\n",
    "mymodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 1s 149us/step - loss: 0.2886 - acc: 0.8628\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0813 - acc: 0.9734\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0603 - acc: 0.9820\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0508 - acc: 0.9851\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0451 - acc: 0.9870\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0426 - acc: 0.9874\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0389 - acc: 0.9889\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0376 - acc: 0.9891\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0349 - acc: 0.9901\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0326 - acc: 0.9909\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0327 - acc: 0.9909\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0307 - acc: 0.9913\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0302 - acc: 0.9914\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0287 - acc: 0.9920\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0278 - acc: 0.9923\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 0s 27us/step - loss: 0.0287 - acc: 0.9919\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 0s 30us/step - loss: 0.0259 - acc: 0.9928\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 0s 33us/step - loss: 0.0263 - acc: 0.9928\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.0248 - acc: 0.9930\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 0s 32us/step - loss: 0.0302 - acc: 0.9913\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0274 - acc: 0.9923\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0237 - acc: 0.9934\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0230 - acc: 0.9937\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0224 - acc: 0.9939\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0214 - acc: 0.9942\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0231 - acc: 0.9933\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0222 - acc: 0.9939\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0214 - acc: 0.9942\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0246 - acc: 0.9931\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0220 - acc: 0.9938\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0209 - acc: 0.9944\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0212 - acc: 0.9941\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0194 - acc: 0.9947\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0206 - acc: 0.9944\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0211 - acc: 0.9942\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0233 - acc: 0.9938\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0208 - acc: 0.9944\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0192 - acc: 0.9947\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0195 - acc: 0.9946\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 0s 26us/step - loss: 0.0194 - acc: 0.9947\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0193 - acc: 0.9946\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.0213 - acc: 0.9942\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0189 - acc: 0.9947\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.0195 - acc: 0.9946\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0183 - acc: 0.9949\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0185 - acc: 0.9950\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0191 - acc: 0.9947\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.0180 - acc: 0.9951\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0181 - acc: 0.9950\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0186 - acc: 0.9950\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0223 - acc: 0.9937\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0202 - acc: 0.9944\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0178 - acc: 0.9952\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0176 - acc: 0.9952\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0171 - acc: 0.9954\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0198 - acc: 0.9945\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0181 - acc: 0.9952\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0188 - acc: 0.9947\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0193 - acc: 0.9946\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0175 - acc: 0.9952\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0170 - acc: 0.9953\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0226 - acc: 0.9936\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0170 - acc: 0.9953\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0160 - acc: 0.9956\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0157 - acc: 0.9958\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0159 - acc: 0.9956\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0155 - acc: 0.9957\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0168 - acc: 0.9956\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0180 - acc: 0.9950\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0182 - acc: 0.9949\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0163 - acc: 0.9955\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 0s 28us/step - loss: 0.0171 - acc: 0.9952\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 0s 21us/step - loss: 0.0159 - acc: 0.9957\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0167 - acc: 0.9954\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0188 - acc: 0.9948\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0210 - acc: 0.9939\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0194 - acc: 0.9947\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0158 - acc: 0.9958\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0148 - acc: 0.9960\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0154 - acc: 0.9958\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0152 - acc: 0.9957\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0157 - acc: 0.9957\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0174 - acc: 0.9953\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0290 - acc: 0.9918\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0157 - acc: 0.9958\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0154 - acc: 0.9958\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0148 - acc: 0.9959\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0145 - acc: 0.9961\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0159 - acc: 0.9957\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0157 - acc: 0.9956\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0172 - acc: 0.9953\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0157 - acc: 0.9957\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0143 - acc: 0.9961\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 0s 25us/step - loss: 0.0152 - acc: 0.9958\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0140 - acc: 0.9962\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 0s 24us/step - loss: 0.0155 - acc: 0.9957\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0226 - acc: 0.9933\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0189 - acc: 0.9948\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 0s 22us/step - loss: 0.0201 - acc: 0.9943\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 0s 23us/step - loss: 0.0143 - acc: 0.9961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x171814107b8>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First train with small mini batch size and default learning rate\n",
    "mymodel.fit(xtrain, ytrain, epochs = 100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'acc']\n",
      "2754/2754 [==============================] - 0s 130us/step\n",
      "[0.022923295400338755, 0.9943355069960385]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the valid dataset\n",
    "print(mymodel.metrics_names)\n",
    "print(mymodel.evaluate(xvalid, yvalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2754\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1718f39a048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check how much points are kept\n",
    "ypredict = mymodel.predict(xvalid)\n",
    "print(len(ypredict))\n",
    "nbPtsPred = np.sum(ypredict>0.5, axis=1)\n",
    "nbPtsTruth = np.sum(yvalid>0.5, axis=1)\n",
    "\n",
    "plt.hist([nbPtsPred,nbPtsTruth], label=['prediction','truth'])\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 0, 0, ..., 0, 0, 6])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
